1、文章：https://zhuanlan.zhihu.com/p/640457255
渐近特征金字塔网络（AFPN）能够支持非相邻层的直接交互
  AFPN是通过融合两个相邻的Low-Level特征来启动的，并渐进地将High-Level特征纳入融合过程。通过这种方式，可以避免非相邻 Level 之间的较大语义差距。考虑到在每个空间位置的特征融合过程中可能出现多目标信息冲突，进一步利用自适应空间融合操作来缓解这些不一致。

  传统的计算机视觉方法通常只从图像中提取一个尺度特征进行分析和处理。这将导致对不同大小的目标或不同尺度的场景的检测性能较差。研究人员已经构建了包含各种尺度特征的特征金字塔，克服了使用单尺度特征的局限性。此外，许多研究提出了特征融合模块，旨在增强或细化特征金字塔网络，进一步提高检测器的性能。
2、基础模型：
          基础模型指通过 大规模数据预训练 、具有广泛适应能力的模型。 这类模型的特点是： 预训练+微调范式：先在海量数据上无监督学习，再通过微调适配到具体任务。

3、论文：1824_Towards_Seamless_Adaptati
  大多数方法需要进行几何验证，该论文尝试使用视觉基础模型不进行几何验证，生成局部特征进行重新排序，进而加快VPR的检索过程

  nlp领域的方法也可以借鉴到cv中

  3项构建基础模型的要素，分别是网络架构，预训练算法，robust learning
  VIT是一种将transformer运用在CV领域的模型

  参数高效迁移学习(PETL):
           主要的PETL方法大致分为三类：添加任务特定适配器、提示调优和低秩适应(LoRA)
          该论文采用添加任务特定适配器的方法，因为他是首批使用混合全局-局部适配来生成全局特征和局部特征，并将其应用于解决VPR挑战的工作之一
1)提出的方法：介绍用于两阶段VPR的提议SelaVPR。首先是ViT及其在生成地点图像表示中的应用。
            然后，提出全局适配、局部适配和局部匹配重排序，以实现两阶段VPR。最后，给出了用于微调的损失函数  

！[img_10.png]  
全局适配的基础模型能够生成专注于判别性地标并忽略动态干扰的特征表示。这拟合了模型预训练与VPR人物之间的差距，并显著提升基础模型在VPR任务中的性能

全局适配的Vit主干网络被用于提取特征图  
![img_11.png]

实验表明：SelaVPR的优秀表现 说明了在极端环境下VPR使用局部匹配（局部适配器）是很有必要的
      得益于视觉基础模型以及合理的适应性微调，使得SelaVPR不需要复杂的训练策略以及专门构建大规模训练数据集  
！[img_12.png]  
要点:重排列局部匹配+参数高效微调 而非全量微调

本文提出一种新方法，实现预训练基础模型在VPR任务中的无缝适配，命名为SelaVPR。通过在冻结的预训练模型上添加少量可调的轻量级适配器，我们实现了高效的混合全局-局部适配，以获取用于检索候选地点的全局特征和用于重排序的局部
特征


先用全局适配筛选出全局特征，然后通过局部适配对这些特征图进行重排列，基线使用视觉基础模型
  1)全局适配在每个transformer块的多头注意力层之后以及与MLP层并行的位置添加适配器  ![img_10.png]  
  2)局部适配通过在整个Transformer主干之后添加卷积层来放大特征图来实现
  3)提出SelaVPR特征表示聚焦于判别性地标，重点用于地点识别，可以自行忽略与区分地点无关的区域
  4)该实验可以直接匹配局部特征，不需要空间验证，使得重排列比主流两阶段VPR方法要快得多
  5)提出互最近邻局部特征损失--->用于训练局部适配模块，并且和全局特征损失结合用于微调，获得的局部特征可以直接用于交叉匹配进行重排序，不需要几何验证

对于参数高效学习，采用添加任务特定适配器的方法，因其使用混合全局局部适配来生成全局特征和局部特征
  主要还是全局适配以及(用于重排序的)局部适配
  ·)局部适配---->得到局部特征
    就是在ViT主干网络之后添加一个上采样模块：该模块由两个上卷积（up-conv）层和中间的一个ReLU层组成。特征图在经过每个上卷积层后，其高度和宽度大约翻倍，而通道维度则减少。
    最终，对于输入尺寸为224×224像素的图像，该模块将ViT-L/14主干网络输出的16×16×1024维特征图调整为61×61×128维，并在通道维度上进行L2归一化（intraL2），得到密集局部特征，即一个
    61×61的128维局部特征网格fl
  ·)用于重排列的局部匹配：
    获得全局特征和局部特征后，先计算L2距离，在数据库的全局特征空间中进行相似性搜索，得到最相似的前k个候选图像。对于查询图像q与候选图像c之间的局部特征匹配通过交叉匹配寻找互最近邻
    匹配。由于局部特征经过L2归一化，使用内积（等价于余弦相似度）来衡量局部特征相似性
    
    最后直接使用匹配数量（即|M|）作为重排序的图像相似性得分
  ·）损失的处理：
  使用三元组损失，进一步的优化网络以使得生成的互匹配局部特征更加相似，因而设计一种互最近邻局部特征损失Ll，该局部损失最大化查询图像与正样本图像之间在互匹配集合M中的平均局部特征相似性，
  并最小化查询图像与负样本图像在匹配集合M′中的相似性。这使得生成的局部特征更适合局部匹配。

    最后通过权重λ将全局损失Lg和局部损失Ll结合，得到最终损失：L = Lg + λLl





















