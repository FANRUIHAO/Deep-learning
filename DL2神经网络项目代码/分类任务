#分类任务：才正式进入深度学习的领域

1.nn.Linear
    作用：随意转换矩阵的维度

    在中间多算几次，可以加深网络加强效果
(1)Then：梯度下降算法
    处理数据集(训练集，验证集，测试集)

(2)分类与回归之间区别就是输出不同
    回归：是找一条线，模拟原有的数据，从给定的x值，预测出y的值

    ·分类：找一条分界线，将数据分为两类，也就是找出两类数据之间的分界线
    ··分类的输出：
            误区：输出一个类别，结果离谁近就属于哪一类

            方法：One-hot独热编码(用01向量表示)
            如：[0,1]表示属于第二类，[1,0]表示属于第一类
            每个元素都代表不同的类别
            看向量最大值所在的下标就是他的类别
    图片分类：将图片转换为向量，然后进行分类
    ··图片分类的方法：
            1.将图片转换为向量（图片大小一般规定为224x224）
            标签y为向量  即概率分布 求分布之间的loss
            2.将向量输入到神经网络中
            3.输出预测值

卷积神经网络：
    即对应矩阵(卷积和)的卷积操作 得到特征图 
    一般只需要关注到小的特征图
    (图片天然就是矩阵)卷积核是三层矩阵在卷积

    因为卷积之后的矩阵会变小，所以需要填充0(即使用ZeroPadding)
    ZeroPaddign卷一层即添加两列，卷两层即添加四列

    卷积核大小不变，但是厚度会变 
    卷积核参数量就是卷积核大小乘以厚度

    如果引入维度，就是引入卷积核 
    一个卷积核就可以卷出来一张特征图

    特征图即卷积核数量*卷出来的特征图大小
    卷积核参数量即卷积核大小*厚度*卷积核数量

    #特征图变小的方法
        降低采集量
        1)扩大步长
            缺点：会丢失信息，还会引入计算
        2)池化(pooling)
            用一个数代表多个数
            ·)最大池化(首选)
            ·)平均池化
    #卷积
        可以用maxpooling(7) #7表示7个数中取最大值
    #卷积完后得到单层或多层特征图
    #特征图展开成向量
    #向量输入到全连接层
    #中间可以任意添加全连接层
        Linear
    #全连接层输出预测值（类别）

分类的loss：
    让标签变成概率分布，然后求分布之间的loss
    nn.softmax() #将向量变成概率分布